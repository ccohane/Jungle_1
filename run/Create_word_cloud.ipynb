{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from PIL import Image\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import TfidfModel\n",
    "from wordcloud import WordCloud\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_sentence(sent):\n",
    "    return({word: True for word in nltk.word_tokenize(sent)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in pd.read_csv(\"review.csv\",chunksize=10000):\n",
    "    x.columns=['funny','user_id','review_id','text','business_id','stars','date','useful','cool']\n",
    "    x.to_csv(\"out2.csv\",index=False, mode='a')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"out2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "\n",
    "def strip_accents(text):\n",
    "    try:\n",
    "        text = unicode(text, 'utf-8')\n",
    "    except NameError: # unicode is a default on python 3 \n",
    "        pass\n",
    "    text = unicodedata.normalize('NFD', text)\n",
    "    text = text.encode('ascii', 'ignore')\n",
    "    text = text.decode(\"utf-8\")\n",
    "    return str(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.047766189578841635), (1, 0.01099359730499089), (2, 0.012179222337392234), (3, 0.028689139829417426), (4, 0.005443014411188002), (5, 0.11351766625148363), (6, 0.11006329380189007), (7, 0.12704261082025087), (8, 0.1773411466579038), (9, 0.13469051928502018), (10, 0.06431551375482468), (11, 0.27243197952906734), (12, 0.021259446315209568), (13, 0.20089851284495985), (14, 0.12263277957123835), (15, 0.060145857649112), (16, 0.15499895963135182), (17, 0.1663489232017021), (18, 0.13852560326376437), (19, 0.12274704927658826), (20, 0.1106003965379117), (21, 0.023989560554101584), (22, 0.06223101407922806), (23, 0.3097703134308544), (24, 0.15045030124295977), (25, 0.12716729427731105), (26, 0.23752144638484665), (27, 0.1279219138361294), (28, 0.14510691228929867), (29, 0.29021382457859735), (30, 0.07921910373922296), (31, 0.136347794041056), (32, 0.1943738618436364), (33, 0.22347347952236676), (34, 0.04599569990291652), (35, 0.18046263620441272), (36, 0.17314716361561602), (37, 0.10750238255249829), (38, 0.12217826286590729), (39, 0.21945379266696857), (40, 0.09934956149475414), (41, 0.015334644468213825), (42, 0.03598952301623271), (43, 0.1807218937136546), (44, 0.18335013993728477), (45, 0.15168878056730245)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<wordcloud.wordcloud.WordCloud at 0x131dc5cd0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_common_surface_form(original_corpus, stemmer):\n",
    "    counts = defaultdict(lambda : defaultdict(int))\n",
    "    surface_forms = {}\n",
    "\n",
    "    for document in original_corpus:\n",
    "        for token in document:\n",
    "            stemmed = stemmer.stem(token)\n",
    "            counts[stemmed][token] += 1\n",
    "\n",
    "    for stemmed, originals in counts.items():\n",
    "        surface_forms[stemmed] = max(originals, \n",
    "                                     key=lambda i: originals[i])\n",
    "\n",
    "    return surface_forms\n",
    "\n",
    "stemmer = PorterStemmer() # Stemmer for reducing terms to root form \n",
    "\n",
    "stemmed_corpus = []       # For storing the stemmed tokens \n",
    "\n",
    "original_corpus = []      # For storing the non-stemmed tokens\n",
    "\n",
    "\n",
    "for x in df['text']:    # Iterate over the files # Load file contents\n",
    "\n",
    "    z= strip_accents(x)\n",
    "    \n",
    "    tokens = word_tokenize(z)     # Extract tokens\n",
    "\n",
    "    stemmed = [stemmer.stem(token) for token in tokens] # Stem tokens\n",
    "\n",
    "    stemmed_corpus.append(stemmed)    # Store stemmed document\n",
    "\n",
    "    original_corpus.append(tokens)    # Store original document\n",
    "\n",
    "\n",
    "dictionary = Dictionary(stemmed_corpus) # Build the dictionary\n",
    "\n",
    "\n",
    "# Get the surface form for each stemmed word\n",
    "\n",
    "counts = get_common_surface_form(original_corpus, stemmer)\n",
    "\n",
    "# Convert to vector corpus\n",
    "\n",
    "vectors = [dictionary.doc2bow(text) for text in stemmed_corpus]\n",
    "\n",
    "# Train TF-IDF model\n",
    "\n",
    "tfidf = TfidfModel(vectors)\n",
    "\n",
    "# Get TF-IDF weights\n",
    "\n",
    "weights = tfidf[vectors[0]]\n",
    "\n",
    "# Replace term IDs with human consumable strings\n",
    "\n",
    "weights = [(counts[dictionary[pair[0]]], pair[1]) for pair in weights]\n",
    "weights=dict(weights)\n",
    "\n",
    "# Initialize the cloud\n",
    "\n",
    "wc = WordCloud(\n",
    "    background_color=\"white\",\n",
    "    max_words=2000,\n",
    "    width=1024,\n",
    "    height=720,\n",
    "    stopwords=stopwords.words('english')\n",
    ")\n",
    "\n",
    "# Generate the cloud\n",
    "\n",
    "wc.generate_from_frequencies(weights)\n",
    "\n",
    "# Save the cloud to a file\n",
    "\n",
    "wc.to_file(\"wordcloud.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
